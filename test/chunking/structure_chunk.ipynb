{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # Testing Extract Text -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdfplumber\n",
    "\n",
    "# file_name = \"./pdfs/ba_56-1_2023.pdf\"\n",
    "# main_file = []\n",
    "# with pdfplumber.open(file_name) as pdf:\n",
    "#     for page in pdf.pages:\n",
    "#         main_file.append(page.extract_text())\n",
    "#     pdf.close()\n",
    "\n",
    "# m_sections = {\n",
    "#     'การประกอบธุรกิจและผลการดำเนินงาน\\nโครงสร้างและการดำเนินงานของกลุ่มบริษัท' : ['ลักษณะการประกอบธุรกิจ (1.2)\\n','นโยบายและภาพรวมการประกอบธุรกิจ (1.1)\\n'],\n",
    "#     'การประกอบธุรกิจและผลการดำเนินงาน\\nการบริหารจัดการความเสี่ยง' : ['ปัจจัยความเสี่ยงต่อการดำเนินธุรกิจของบริษัท (2.2)\\n', 'นโยบายและแผนการบริหารความเสี่ยง (2.1)\\n'],\n",
    "#     'การประกอบธุรกิจและผลการดำเนินงาน\\nการขับเคลื่อนธุรกิจเพื่อความยั่งยืน' : ['การจัดการความยั่งยืนในมิติสังคม (3.4)\\n', 'การจัดการด้านความยั่งยืนในมิติสิ่งแวดล้อม (3.3)\\n', 'การจัดการผลกระทบต่อผู้มีส่วนได้เสียในห่วงโซ่คุณค่าของธุรกิจ (3.2)\\n', 'นโยบายและเป้าหมายการจัดการด้านความยั่งยืน (3.1)\\n'],\n",
    "#     'การกำกับดูแลกิจการ\\nนโยบายการกำกับดูแลกิจการ' : ['การเปลี่ยนแปลงและพัฒนาการที่สำคัญของนโยบาย แนวปฏิบัติ และระบบการกำกับดูแลกิจการในรอบปี ที่ผ่านมา (6.3)\\n', 'จรรยาบรรณธุรกิจ (6.2)\\n', 'ภาพรวมของนโยบายและแนวปฏิบัติการกำกับดูแลกิจการ (6.1)\\n'],\n",
    "#     'การกำกับดูแลกิจการ\\nโครงสร้างการกำกับดูแลกิจการ\\nและข้อมูลสำคัญเกี่ยวกับ\\nคณะกรรมการ คณะกรรมการชุดย่อย ผู้บริหาร\\nพนักงานและอื่นๆ': ['ข้อมูลสำคัญอื่นๆ (7.6)\\n', 'ข้อมูลเกี่ยวกับพนักงาน (7.5)\\n', 'ข้อมูลเกี่ยวกับผู้บริหาร (7.4)\\n', 'ข้อมูลเกี่ยวกับคณะกรรมการชุดย่อย (7.3)\\n', 'ข้อมูลเกี่ยวกับคณะกรรมการ (7.2)\\n', 'โครงสร้างการกำกับดูแลกิจการ (7.1)\\n'],\n",
    "#     'การกำกับดูแลกิจการ\\nรายงานผลการดำเนินงานสำคัญ\\nด้านการกำกับดูแลกิจการ' : ['สรุปผลการปฏิบัติหน้าที่ของคณะกรรมการชุดย่อยอื่นๆ (8.3)\\n', 'รายงานผลการปฏิบัติหน้าที่ของคณะกรรมการตรวจสอบในรอบปีที่ผ่านมา (8.2)\\n', 'สรุปผลการปฏิบัติหน้าที่ของคณะกรรมการในรอบปีที่ผ่านมา (8.1)\\n'],\n",
    "#     'การกำกับดูแลกิจการ\\nการควบคุมภายในและรายการระหว่างกัน' : ['รายการระหว่างกัน (9.2)\\n', 'สรุปผลการปฏิบัติหน้าที่ของคณะกรรมการในรอบปีที่ผ่านมา (8.1)\\n'],\n",
    "# }\n",
    "\n",
    "# buffer = {}\n",
    "# current_section = None\n",
    "# for d in main_file[2:len(main_file)]:\n",
    "#     for section in m_sections:\n",
    "#         if section in d:\n",
    "#             current_section = section\n",
    "#             buffer[section] = \"\"\n",
    "#             break\n",
    "\n",
    "#     if current_section:\n",
    "#         d = d + '[END_PAGE]'\n",
    "#         buffer[current_section] += d\n",
    "\n",
    "\n",
    "# m_buffer = {}\n",
    "# def cut_paragraph(text_input:str, dict_input):\n",
    "#     split = dict_input.split(text_input)\n",
    "#     if len(split) > 1:\n",
    "#         split[1] = text_input + split[1]\n",
    "#     return split\n",
    "\n",
    "# for m_section in m_sections:\n",
    "#     sub_section_chunks = []     # Chunk For Storage Sub Section\n",
    "#     chunk_buffer = []           # Chunk Buffer During Segmentation\n",
    "\n",
    "#     if m_section in buffer:\n",
    "#         paragraph = buffer[m_section].replace(m_section + '[END_PAGE]', \"\")\n",
    "#     else:\n",
    "#         continue\n",
    "\n",
    "#     for sub in m_sections[m_section]:\n",
    "#         if chunk_buffer == []:\n",
    "#             chunk_buffer = paragraph\n",
    "\n",
    "#         a = cut_paragraph(sub, chunk_buffer)\n",
    "#         if len(a) > 1:\n",
    "#             sub_section_chunks.insert(0, a[1])\n",
    "        \n",
    "#         chunk_buffer = a[0]\n",
    "\n",
    "#     m_buffer[m_section] = sub_section_chunks\n",
    "#     sub_section_chunks = []                     # Clear Chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Buffer Data for Compute Extract Table -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(m_buffer['การประกอบธุรกิจและผลการดำเนินงาน\\nโครงสร้างและการดำเนินงานของกลุ่มบริษัท'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Find Table in Buffer -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from s56in1 import extractor56Section7V1\n",
    "\n",
    "# extract_section7 = extractor56Section7V1(file_name, m_buffer['การกำกับดูแลกิจการ\\nโครงสร้างการกำกับดูแลกิจการ\\nและข้อมูลสำคัญเกี่ยวกับ\\nคณะกรรมการ คณะกรรมการชุดย่อย ผู้บริหาร\\nพนักงานและอื่นๆ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in extract_section7:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_buffer['การกำกับดูแลกิจการ\\nโครงสร้างการกำกับดูแลกิจการ\\nและข้อมูลสำคัญเกี่ยวกับ\\nคณะกรรมการ คณะกรรมการชุดย่อย ผู้บริหาร\\nพนักงานและอื่นๆ'] = extract_section7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in m_buffer:\n",
    "#     for j in m_buffer[i]:\n",
    "#         print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from metadatas import generateMetadata\n",
    "\n",
    "# con = m_buffer['การประกอบธุรกิจและผลการดำเนินงาน\\nโครงสร้างและการดำเนินงานของกลุ่มบริษัท']\n",
    "\n",
    "# f = generateMetadata(file_name, 'การประกอบธุรกิจและผลการดำเนินงาน\\nโครงสร้างและการดำเนินงานของกลุ่มบริษัท', con)\n",
    "\n",
    "# for k in m_buffer:\n",
    "#     generateMetadata(file_name, k, m_buffer[k])\n",
    "\n",
    "# generateMetadata(file_name, \"การกำกับดูแลกิจการ\\nโครงสร้างการกำกับดูแลกิจการ\\nและข้อมูลสำคัญเกี่ยวกับ\\nคณะกรรมการ คณะกรรมการชุดย่อย ผู้บริหาร\\nพนักงานและอื่นๆ\", m_buffer['การกำกับดูแลกิจการ\\nโครงสร้างการกำกับดูแลกิจการ\\nและข้อมูลสำคัญเกี่ยวกับ\\nคณะกรรมการ คณะกรรมการชุดย่อย ผู้บริหาร\\nพนักงานและอื่นๆ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.text_splitter import SemanticChunker\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = SemanticChunker(\n",
    "#     embedding_model, breakpoint_threshold_type=\"gradient\"\n",
    "# )\n",
    "\n",
    "# # for key in m_buffer:\n",
    "# #     # for d in m_buffer[key]:\n",
    "# #     docs = text_splitter.create_documents(m_buffer[key])\n",
    "# #     print(docs)\n",
    "\n",
    "# docs = text_splitter.create_documents(m_buffer['การประกอบธุรกิจและผลการดำเนินงาน\\nโครงสร้างและการดำเนินงานของกลุ่มบริษัท'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# import re\n",
    "\n",
    "# def split_text_by_n_occurrence(text):\n",
    "#     a = \"\"\n",
    "#     b = []\n",
    "#     buffer = text.split(\"-----\\n\")\n",
    "#     counter = 0\n",
    "#     for index in range(0, len(buffer)):\n",
    "#         if re.search(r\"^ข้อมูลทั่วไป\", buffer[index]):\n",
    "#             a += buffer[index]\n",
    "#             counter += 1\n",
    "#         else:\n",
    "#             if a != \"\":\n",
    "#                 b.append(a)\n",
    "#                 b.append(buffer[index])\n",
    "#                 a = \"\"\n",
    "#             else:\n",
    "#                 b.append(buffer[index])\n",
    "#             counter = 0\n",
    "#         if counter == 3:\n",
    "#             b.append(a)\n",
    "#             a = \"\"\n",
    "#             counter = 0\n",
    "    \n",
    "#     return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from metadatas import gptCalToken, semantic_chunking\n",
    "# from langchain_core.documents import Document\n",
    "\n",
    "# def createDocuments(file_path: str, text):\n",
    "#     path = file_path.split(\"/\")\n",
    "#     file_name = path[-1]\n",
    "#     company_name, file_type, year = file_name.split(\"_\")\n",
    "\n",
    "#     company_name = company_name.upper()\n",
    "#     year = year.split(\".\")[0]\n",
    "\n",
    "\n",
    "#     documents = []\n",
    "\n",
    "#     metadata = {\n",
    "#         \"company_name\": company_name,\n",
    "#         \"file_type\": file_type,\n",
    "#         \"year\": year,\n",
    "#         \"structured\": True,\n",
    "#     }\n",
    "\n",
    "#     for key in text:\n",
    "#         section = key.split(\"\\n\",1)[1]\n",
    "#         file_metadata = metadata\n",
    "#         file_metadata[\"section\"] = section\n",
    "\n",
    "#         for data in text[key]:\n",
    "#             # print(\"SEC\", section)\n",
    "#             sub_section = data.split(\"\\n\", 1)[0]\n",
    "#             # print(\"SUB\", sub_section)\n",
    "#             metadata[\"sub_section\"] = sub_section\n",
    "\n",
    "#             # 7\n",
    "#             if (section == \"โครงสร้างการกำกับดูแลกิจการ\\nและข้อมูลสำคัญเกี่ยวกับ\\nคณะกรรมการ คณะกรรมการชุดย่อย ผู้บริหาร\\nพนักงานและอื่นๆ\"):            \n",
    "#                 for i in split_text_by_n_occurrence(data):\n",
    "#                     # print([i])\n",
    "#                     document = Document(\n",
    "#                         page_content=i,\n",
    "#                         metadata=file_metadata\n",
    "#                     )\n",
    "#                     documents.append(document)\n",
    "#                 # print(\"\\n\")\n",
    "\n",
    "#             # 1, 2, 3, 6, 8\n",
    "#             else:\n",
    "#                 # pass\n",
    "#                 for i in semantic_chunking(data):\n",
    "#                     document = Document(\n",
    "#                         page_content=i,\n",
    "#                         metadata=file_metadata\n",
    "#                     )\n",
    "#                     documents.append(document)\n",
    "#                     # print([i])\n",
    "#                     # print(gptCalToken(i))\n",
    "#                 # print(\"\\n\")\n",
    "#         # print(\"====\")\n",
    "#     return documents\n",
    "\n",
    "\n",
    "# documents = createDocuments(\"./pdfs/bts_56-1_2023.pdf\",m_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'extractPdf' from 'extractor' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../extraction/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mextractor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extractPdf, createDocuments\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# from s56in1 import extractor56Section7V1\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# file_name = \"./pdfs/true_56-1_2023.pdf\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# documents = createDocuments(file_name, buffer)\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'extractPdf' from 'extractor' (unknown location)"
     ]
    }
   ],
   "source": [
    "from extractor import extractPdf, createDocuments\n",
    "from s56in1 import extractor56Section7V1\n",
    "\n",
    "file_name = \"./pdfs/true_56-1_2023.pdf\"\n",
    "buffer = extractPdf(file_path=file_name)\n",
    "\n",
    "section7 = extractor56Section7V1(file_name, buffer['การกำกับดูแลกิจการ\\nโครงสร้างการกำกับดูแลกิจการ\\nและข้อมูลสำคัญเกี่ยวกับ\\nคณะกรรมการ คณะกรรมการชุดย่อย ผู้บริหาร\\nพนักงานและอื่นๆ'])\n",
    "buffer['การกำกับดูแลกิจการ\\nโครงสร้างการกำกับดูแลกิจการ\\nและข้อมูลสำคัญเกี่ยวกับ\\nคณะกรรมการ คณะกรรมการชุดย่อย ผู้บริหาร\\nพนักงานและอื่นๆ'] = section7\n",
    "\n",
    "documents = createDocuments(file_name, buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CORE] Initializing Milvus Database Core...\n",
      "[DB] init Embedding Model...\n",
      "[DB] init Embedding Model Successfully.\n",
      "[DB] Found Database: new_core\n",
      "[DB] Found Collection \"cnode_1\".\n",
      "[DB] Drop Collection \"cnode_1\"...\n",
      "cnode_1 has: 38 entities\n",
      "[DB] Drop Collection \"cnode_1\" Successfully.\n",
      "[DB] Create Collection \"cnode_1\"\n",
      "[DB] Collection \"cnode_1\" Is Ready.\n",
      "[DB] Found Collection \"gnode_1\".\n",
      "[DB] Drop Collection \"gnode_1\"...\n",
      "gnode_1 has: 40 entities\n",
      "[DB] Drop Collection \"gnode_1\" Successfully.\n",
      "[DB] Create Collection \"gnode_1\"\n",
      "[DB] Collection \"gnode_1\" Is Ready.\n",
      "[DB] Found Collection \"frontend_query_general_documents\".\n",
      "[DB] Drop Collection \"frontend_query_general_documents\"...\n",
      "frontend_query_general_documents has: 1 entities\n",
      "[DB] Drop Collection \"frontend_query_general_documents\" Successfully.\n",
      "[DB] Create Collection \"frontend_query_general_documents\"\n",
      "[DB] Collection \"frontend_query_general_documents\" Is Ready.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pymilvus import db\n",
    "sys.path.insert(1, '../milvus/')\n",
    "\n",
    "from core import Core\n",
    "from schema import DATA_SOURCE_SCHEMA\n",
    "\n",
    "\n",
    "core = Core(\n",
    "    # collection_name=\"s56in1V1\",\n",
    "    database_name=\"new_core\",\n",
    "    schema=DATA_SOURCE_SCHEMA,\n",
    "    dense_embedding_model=embedding_model,\n",
    "    token=\"root:Milvus\",\n",
    "    # system_prune=True\n",
    "    create_first_node=True,\n",
    "    system_prune_first_node=True\n",
    ")\n",
    "\n",
    "# print(db.list_database())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n",
      "Collection gnode_1:\n",
      "Partition in gnode_1 : _default has 0 entities\n",
      "Partition in gnode_1 : ndc has 20 entities\n",
      "Collection cnode_1:\n",
      "Partition in cnode_1 : _default has 0 entities\n",
      "Partition in cnode_1 : bts has 38 entities\n",
      "Partition in cnode_1 : true has 39 entities\n",
      "Collection frontend_query_general_documents:\n",
      "Partition in frontend_query_general_documents : _default has 1 entities\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import Collection\n",
    "print(\"====\")\n",
    "for collection in core.listCollection():\n",
    "    print(f\"Collection {collection}:\")\n",
    "    # print(core.listPartition(collection))\n",
    "    for p in core.listPartition(collection):\n",
    "        c = Collection(name=collection).partition(p).num_entities\n",
    "        print(\"Partition in\", collection, \":\", p, \"has\", c, \"entities\")\n",
    "print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Collection>:\n",
      "-------------\n",
      "<name>: cnode_1\n",
      "<description>: Schema for Data Source Collection\n",
      "<schema>: {'auto_id': True, 'description': 'Schema for Data Source Collection', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'dense_vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 1024}}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 8192}}, {'name': 'metadata', 'description': '', 'type': <DataType.JSON: 23>}], 'enable_dynamic_field': True}\n",
      "\n",
      "<class 'pymilvus.orm.collection.Collection'>\n",
      "[DB] Commit new Company\n",
      "[DB] Create New Partition\n",
      "[DB] Partition true: 39 entities\n"
     ]
    }
   ],
   "source": [
    "core.add_document(name=\"true\", documents=documents, node_type=\"c\", sector_id=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = [\"scb\"]\n",
    "# config ={\n",
    "#     \"k\": 8,\n",
    "#     \"partition_names\": name,\n",
    "#     # \"expr\": '(metadata[\"year\"] == \"2023\" && metadata[\"company_name\"] == \"SCB\") || (metadata[\"year\"] == \"2023\" && metadata[\"company_name\"] == \"BTS\")'\n",
    "# }\n",
    "# chunk_retreiver = core.initVectorStore(collection_name=\"cnode_1\", partition_names=name, search_kwargs=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = chunk_retreiver.invoke(\"bts คืออะไร\")\n",
    "# for i in dat:\n",
    "#     print([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection\n",
    "\n",
    "collection = Collection(\"cnode_1\")\n",
    "collection.load()\n",
    "\n",
    "# Fetch 5 sample records to check metadata format\n",
    "results = collection.query(\n",
    "    expr=\"\",\n",
    "    output_fields=[\"metadata\", \"_partition\"],\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "for i in results:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# system_prompt = \"\"\"\n",
    "#     You are STELLA, a helpful search assistant trained by Peerasit Ployaram.\n",
    "\n",
    "#     # General Instructions\n",
    "\n",
    "#     Write an accurate, detailed, and comprehensive response to the user's query located at INITIAL_QUERY.\n",
    "#     Additional context is provided as \"USER_INPUT\" after specific questions.\n",
    "#     Your answer must be precise, of high-quality, and written by an expert using an unbiased and journalistic tone.\n",
    "#     Your answer must be written in the same language as the query, even if language preference is different.\n",
    "\n",
    "#     You MUST NEVER use moralization or hedging language. AVOID using the following phrases:\n",
    "\n",
    "#     - \"It is important to ...\"\n",
    "#     - \"It is inappropriate ...\"\n",
    "#     - \"It is subjective ...\"\n",
    "\n",
    "#     You MUST ADHERE to the following formatting instructions:\n",
    "\n",
    "#     - Use markdown to format paragraphs, lists, tables, and quotes whenever possible.\n",
    "#     - Use headings level 2 and 3 to separate sections of your response, like \"## Header\", but NEVER start an answer with a heading or title of any kind.\n",
    "#     - Use single new lines for lists and double new lines for paragraphs.\n",
    "#     - Use markdown to render images given in the search results.\n",
    "#     - NEVER write URLs or links.\n",
    "\n",
    "#     If no context you must use answer \"can't answer this question\"\n",
    "# \\n\\n\n",
    "# {context}\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", system_prompt),\n",
    "#         (\"human\", \"{question}\"),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# rag_llm = ChatOpenAI(model=\"gpt-3.5-turbo\",\n",
    "#         api_key=\"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\",\n",
    "#         temperature=0.7, max_tokens=4096)\n",
    "# # Post-processing\n",
    "# def format_docs(docs):\n",
    "#     return \"\\\\n\\\\n\".join(doc.page_content for doc in docs)\n",
    "# # Chain\n",
    "# rag_chain = prompt | rag_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from extraction.query_extractor import query_extractorV1\n",
    "# from extraction.query_extractor import decompose_query\n",
    "# import re\n",
    "\n",
    "# # user_input = \"bts และ advanc ต่างกันยังไง\"\n",
    "# # subs = decompose_query(user_input)\n",
    "# subs = ['รายได้ advanc ในปี 2023']\n",
    "\n",
    "# buffer = []\n",
    "# for query in subs:\n",
    "#     q = re.sub(pattern='[0-9]+\\\\.', repl=\"\", string=query)\n",
    "#     o = query_extractorV1(q)\n",
    "#     print(o)\n",
    "#     if o:\n",
    "#         for i in o:\n",
    "#             # print(i[\"filters\"])\n",
    "#             config ={\n",
    "#                 \"k\": 4,\n",
    "#                 \"partition_names\": [i[\"partition_name\"]],\n",
    "#                 # \"expr\": '(metadata[\"year\"] == \"2023\" && metadata[\"company_name\"] == \"SCB\") || (metadata[\"year\"] == \"2023\" && metadata[\"company_name\"] == \"BTS\")'\n",
    "#                 \"expr\": f\"metadata['year'] == '{i[\"filters\"]}'\"\n",
    "#             }\n",
    "#             retriever = core.initVectorStore(collection_name=i[\"collection_name\"], partition_names=[i[\"partition_name\"]], search_kwargs=config)\n",
    "#             print(q)\n",
    "#             print(i)\n",
    "#             buffer += retriever.invoke(query)\n",
    "#             # buffer.append(retriever.invoke(query))\n",
    "#     else:\n",
    "#         buffer.append(\"no context\")\n",
    "\n",
    "# # out = (rag_chain.invoke({\"context\": buffer, \"question\": user_input}))\n",
    "# # print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = (rag_chain.invoke({\"context\": buffer, \"question\": user_input}))\n",
    "\n",
    "# print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
